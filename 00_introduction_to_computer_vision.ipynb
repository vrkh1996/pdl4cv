{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert\">\n",
    "<div style=\"direction:ltr;text-align:center;font-family: B Tahoma; font-size:24pt\"> Practical Deep Learning Course for Computer Vision\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert\">\n",
    "<div style=\"direction:ltr;text-align:left;font-family:Tahoma; font-size:16pt\"> Introduction to Computer Vision\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "In order to install required libraries, execute cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Import the required libraries.<br>\n",
    "To work with images, we need to import <strong>OpenCV</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1"
    }
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import OpenCv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.3\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "<strong>I/O operations:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Loading an image:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('./images/flower.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Displaying the loaded image:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "cv2.imshow('Flower', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Writing the image on the disk:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the image\n",
    "cv2.imwrite('flower-copy.jpg', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Using the webcam:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if \"0\" is passed to \"VideoCapture\" the source will be the webcam\n",
    "#       and if the address of a video file is passed to \"VideoCapture\" the source will be that video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "<strong>Simple operations on the image:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Image as a matrix:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 552, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the Image: 368 pixels\n",
      "Width of the Image:  552 pixels\n",
      "Channel(s) of the Image:  3 channel(s)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of the image\n",
    "print ('Height of the Image:', image.shape[0], 'pixels')\n",
    "print ('Width of the Image: ', image.shape[1], 'pixels')\n",
    "print ('Channel(s) of the Image: ', image.shape[2], 'channel(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Converting the colored image to greyscale:<br>\n",
    "<strong>Grayscaling</strong> is the process by which an image is converted from a full color to shades of gray.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert to grayscale, use \"cvtColor\"\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Grayscale Flower', gray_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 552)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Individual channels in the RGB image:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"split\" function splits the image into each dimension\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "# Create a matrix of zeros with dimensions of height and width\n",
    "zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "\n",
    "# Note: In OpenCV, the images are in the form of BGR (NOT RGB)\n",
    "cv2.imshow(\"Red Channel\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.waitKey()\n",
    "cv2.imshow(\"Green Channel\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.waitKey()\n",
    "cv2.imshow(\"Blue Channel\", cv2.merge([B, zeros, zeros]))\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Pixel values in the image:<br>\n",
    "As you can see the range for each pixel value is between 0 to 255.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201, 157, 194], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221, 177, 214], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[200, 300] + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146,  58, 132], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[200, 300] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "<strong>Draw shapes or put text on the image:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Line:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "# Draw a line\n",
    "cv2.line(image, (0,0), (400,400), (0,255,0), 5)\n",
    "\n",
    "cv2.imshow(\"Line\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Rectangle:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "# Draw a Rectangle\n",
    "cv2.rectangle(image, (50,100), (300,250), (255,0,0), 5)\n",
    "\n",
    "cv2.imshow(\"Rectangle\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Circle:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "# Draw a Cicle\n",
    "cv2.circle(image, (200, 200), 100, (50,0,255), 5)\n",
    "\n",
    "cv2.imshow(\"Circle\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Text:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "# Put a text\n",
    "cv2.putText(image, 'This is a flower!', (10,50), cv2.FONT_HERSHEY_COMPLEX, 1, (200,170,100), 2)\n",
    "\n",
    "cv2.imshow(\"Text\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "<strong>Image Transformations:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Translation:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Store height and width of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "  \n",
    "#  T  = | 1 0 Tx |\n",
    "#       | 0 1 Ty |\n",
    "\n",
    "# T is our translation matrix\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1,quarter_height]])\n",
    "\n",
    "# Use warpAffine to transform the image using the matrix T\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Rotation:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Store height and width of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "half_height, half_width = height/2, width/2\n",
    "\n",
    "# T is the rotation matrix\n",
    "T = cv2.getRotationMatrix2D((half_width, half_height), 20, 1)\n",
    "\n",
    "# Use warpAffine to rotate the image using the matrix T around its centre\n",
    "rotated_image = cv2.warpAffine(image, T, (width, height))\n",
    "\n",
    "cv2.imshow('Rotation', rotated_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Transpose:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Use \"transpose\" method to flip a the image over its diagonal (switches the row and column indices of the matrix)\n",
    "rotated_image = cv2.transpose(image)\n",
    "\n",
    "cv2.imshow('Rotation - Method 2', rotated_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Flip:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Horizontal flip\n",
    "flipped = cv2.flip(image, 1)\n",
    "\n",
    "cv2.imshow('Horizontal Flip', flipped) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Vertical flip\n",
    "flipped = cv2.flip(image, 0)\n",
    "\n",
    "cv2.imshow('Vertical Flip', flipped) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Horizontal and Vertical flip\n",
    "flipped = cv2.flip(image, -1)\n",
    "\n",
    "cv2.imshow('Horizontal and Vertical Flip', flipped) \n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Resize:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image) \n",
    "cv2.waitKey()\n",
    "\n",
    "# Make the image half of it's original size\n",
    "image_scaled = cv2.resize(image, None, fx=0.5, fy=0.5)\n",
    "cv2.imshow('Scaling - Linear Interpolation', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Make the image double the size of it's original size\n",
    "# Note: You can use different \"interpolation(s)\"\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Resizing by setting exact dimensions\n",
    "img_scaled = cv2.resize(image, (300, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Size of (300, 400)', img_scaled) \n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Crop:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Crop out the arbitray area\n",
    "cropped = image[100:300 , 200:800, :]\n",
    "\n",
    "cv2.imshow(\"Cropped\", cropped)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "<strong>Advanced operations on the image:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Convolution:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/Convolution_schematic.gif\" alt=\"Convolution Schematic\">\n",
    "<a href=\"https://i.pinimg.com/originals/19/c2/3b/19c23b1be24b010884a0238def115b86.gif\">Reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: By passing \"0\" to \"imread\" method, the image will be read in grayscale format\n",
    "image = cv2.imread('./images/flower.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Resize the image to reduce the computation for convolution!\n",
    "img_scaled = cv2.resize(image, (300, 300), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow('Resized', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Creating a 3 x 3 kernel\n",
    "# Note:  Moving Average Filter \n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "# Use the \"fitler2D\" method to conovlve the kernal on the image \n",
    "blurred_3x3 = cv2.filter2D(img_scaled, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred_3x3)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Creating a 7 x 7 kernel\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred_7x7 = cv2.filter2D(img_scaled, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred_7x7)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Sharpening:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg')\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey() \n",
    "\n",
    "# Create our shapening kernel\n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1,9,-1], \n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "# applying the kernel to the input image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "\n",
    "cv2.imshow('Sharpening', sharpened)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Binary Thereshold:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey() \n",
    "\n",
    "# Values below 127 goes to 0 (black) and everything above 127 goes to 255 (white)\n",
    "ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Binary Threshold', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Erosion, Dilation, Opening and Closing:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/morphology.gif\" alt=\"Convolution Schematic\">\n",
    "<a href=\"https://www.dspguide.com/graphics/F_25_10.gif\">Reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey() \n",
    "\n",
    "# The kernel\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# erosion\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.waitKey()\n",
    "\n",
    "# dilation\n",
    "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
    "cv2.imshow('Dilation', dilation)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Closing - Good for removing noise\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:ltr;text-align:left;font-family: Tahoma\">\n",
    "Canny Filter:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/canny2.png\" alt=\"Canny  Filter for Edge Detection\">\n",
    "<a href=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ-Rsl7ZWVFh126U9AZ2WiaqE2I6wisV-vb9wJy_GS5k92sobyc\">Reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/flower.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Canny  Filter for Edge Detection\n",
    "canny = cv2.Canny(image, 60, 120)\n",
    "\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert\">\n",
    "<div style=\"direction:ltr;text-align:left;font-family:B Tahoma\"> Practical Deep Learning Course for Computer Vision\n",
    "<br>Vahid Reza Khazaie<br>\n",
    "</div>\n",
    "<a href=\"https://www.linkedin.com/in/vahidrezakhazaie/\">LinkedIn</a> - <a href=\"https://github.com/vrkh1996\">GitHub</a>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nbpresent": {
   "slides": {
    "300ee14f-a043-486e-b274-7ff253907cd7": {
     "id": "300ee14f-a043-486e-b274-7ff253907cd7",
     "prev": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "regions": {
      "26dc3f39-a230-447c-af4c-f5e5b2fb7835": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c58440a5-3f8f-4f37-9c79-6bf766209406",
        "part": "whole"
       },
       "id": "26dc3f39-a230-447c-af4c-f5e5b2fb7835"
      }
     }
    },
    "878aa53a-1444-4100-8f50-7a408191c579": {
     "id": "878aa53a-1444-4100-8f50-7a408191c579",
     "prev": null,
     "regions": {
      "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "588ee1fa-64b5-453b-ade7-8e6b2515821c",
        "part": "whole"
       },
       "id": "a6c6843a-5ea6-4fbc-b890-3b4b8ae475b3"
      }
     }
    },
    "92e1449b-15f5-40ac-89eb-9496a06af0b0": {
     "id": "92e1449b-15f5-40ac-89eb-9496a06af0b0",
     "prev": "300ee14f-a043-486e-b274-7ff253907cd7",
     "regions": {
      "ea2d28ea-4686-4b1c-832c-836c35a7524e": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "ea2d28ea-4686-4b1c-832c-836c35a7524e"
      }
     }
    },
    "96ffe88e-7b50-43de-afdd-942e564f4e3e": {
     "id": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "prev": "878aa53a-1444-4100-8f50-7a408191c579",
     "regions": {
      "b7e52e12-489a-468d-b10c-af2024fd2856": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de829a92-1fb6-44ad-a2c6-fc1001e1f6e1",
        "part": "whole"
       },
       "id": "b7e52e12-489a-468d-b10c-af2024fd2856"
      }
     }
    },
    "cb74e0bc-4513-4d13-b7f1-14c3078a7927": {
     "id": "cb74e0bc-4513-4d13-b7f1-14c3078a7927",
     "prev": "96ffe88e-7b50-43de-afdd-942e564f4e3e",
     "regions": {
      "444878ee-68f3-4abb-acff-a7079b21e86d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "25f3f538-1ee8-4d98-a6bb-14cbeb7a702d",
        "part": "whole"
       },
       "id": "444878ee-68f3-4abb-acff-a7079b21e86d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
